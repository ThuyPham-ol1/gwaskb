{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will evaluate the relations extracted in all the other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import cPickle\n",
    "import numpy as np\n",
    "\n",
    "# import snorkel and gwaskb\n",
    "sys.path.append('../snorkel')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/crawler')\n",
    "\n",
    "# set up paths\n",
    "abstract_dir = '../data/db/papers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load documents ids from paper/phenotype relation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 paper ids loaded, e.g.:\n",
      "['25086665', '23349640', '20436471', '24714607', '22174851']\n"
     ]
    }
   ],
   "source": [
    "pmids = list()\n",
    "with open('results/nb-output/phenotypes.extracted.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, _ = line.strip().split('\\t')\n",
    "        pmids.append(pmid)\n",
    "        \n",
    "print len(pmids), 'paper ids loaded, e.g.:'\n",
    "print pmids[:5]                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading results from other notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to collect the relations that have been extracted by the previous modules. \n",
    "\n",
    "The paths below point to pre-computed results; you will need to modify these paths to run them on your own input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phenotype/rsid relations from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156 loaded, e.g.:\n",
      "[(('21738491', 1, 3, 2), ('rs12143842', 'QT')), (('17903301', 1, 55, 1), ('rs7544568', 'Aortic root diameter')), (('20585627', 2, 8, 1), ('rs12931267', 'Red hair')), (('17903306', 4, 31, 1), ('rs2195926', 'SDNN')), (('17903301', 2, 9, 1), ('rs10514431', 'left ventricular diastolic dimension'))]\n"
     ]
    }
   ],
   "source": [
    "phen_table_associations = dict()\n",
    "with open('results/nb-output/phen-rsid.table.rel.all.tsv') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        pmid, rsid, phen, pval, _, table_id, row_id, col_id = fields\n",
    "        pval, table_id, row_id, col_id = float(pval), int(table_id), int(row_id), int(col_id)\n",
    "        # note that we assume that an rsid at a givel location will correspond to 1 phenotype\n",
    "        phen_table_associations[pmid, table_id, row_id, col_id] = (rsid, phen)\n",
    "        \n",
    "print len(phen_table_associations), 'loaded, e.g.:'\n",
    "print phen_table_associations.items()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PMID/Phenotype relations extracted from titles/abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 phenotypes loaded, e.g.:\n",
      "[('23738518', 'Reading|Language'), ('22044751', 'Chronic Kidney Disease'), ('21298047', 'European-Origin|Substance Dependence'), ('23104006', 'Endometriosis'), ('20072603', 'Osteoporosis')]\n"
     ]
    }
   ],
   "source": [
    "phen_text_associations = dict()\n",
    "with open('results/nb-output/phenotypes.extracted.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, phen = line.strip().split('\\t')\n",
    "        phen_text_associations[pmid] = phen\n",
    "        \n",
    "print len(phen_text_associations), 'phenotypes loaded, e.g.:'\n",
    "print phen_text_associations.items()[:5]                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSID/Pvalue relations extracted from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9918 relations loaded, e.g.:\n",
      "[(('22504420', 0, 33, 0, 'rs4790881'), set([-7.769551, -10.920819, -5.769551, -3.221849, -8.468521, -18.008774])), (('22396660', 1, 6, 1, 'rs11746443'), set([-0.008774])), (('24094242', 1, 19, 0, 'rs7267979'), set([-9.130768])), (('17903307', 1, 63, 1, 'rs2906966'), set([-5.080399, -4.298432])), (('17903294', 2, 20, 1, 'rs727979'), set([-4.585027, -5.124939]))]\n"
     ]
    }
   ],
   "source": [
    "pval_table_associations = dict()\n",
    "with open('results/nb-output/pval-rsid.filtered.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, rsid, table_id, row_id, col_id, pval = line.strip().split('\\t')\n",
    "        pval, table_id, row_id, col_id = float(pval), int(table_id), int(row_id), int(col_id)\n",
    "        \n",
    "        key = pmid, table_id, row_id, col_id, rsid\n",
    "        if key not in pval_table_associations: pval_table_associations[key] = set()\n",
    "        pval_table_associations[key].add(pval)\n",
    "\n",
    "print len(pval_table_associations), 'relations loaded, e.g.:'\n",
    "print pval_table_associations.items()[:5]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790 suspcious table ids loaded, e.g.:\n",
      "[('21273288', 1), ('19343178', 1), ('23886662', 6), ('23028341', 2), ('23844046', 3)]\n"
     ]
    }
   ],
   "source": [
    "non_gwas_tables = set()\n",
    "with open('results/nb-output/table-annotations.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, table_id, pval_found, lod_found = line.strip().split('\\t')\n",
    "        if int(pval_found) or int(lod_found):\n",
    "            non_gwas_tables.add((pmid, int(table_id)))\n",
    "                                  \n",
    "print len(non_gwas_tables), 'suspcious table ids loaded, e.g.:'\n",
    "print list(non_gwas_tables)[:5]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Singleton RSids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12309 loaded, e.g.:\n",
      "[(('20838585', 0, 18, 3), 'rs6829649'), (('23128233', 0, 17, 2), 'rs9264942'), (('23754948', 1, 6, 0), 'rs10478424'), (('25129146', 0, 8, 0), 'rs1642764'), (('17903301', 2, 9, 1), 'rs10514431')]\n"
     ]
    }
   ],
   "source": [
    "singleton_associations = dict()\n",
    "with open('results/nb-output/rsids.singletons.all.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, table_id, row_id, col_id, rsid = line.strip().split()\n",
    "        table_id, row_id, col_id = int(table_id), int(row_id), int(col_id)\n",
    "        singleton_associations[pmid, table_id, row_id, col_id] = rsid\n",
    "\n",
    "print len(singleton_associations), 'loaded, e.g.:'\n",
    "print singleton_associations.items()[:5]\n",
    "\n",
    "n_singletons_by_table = dict()\n",
    "for (pmid, table_id, row_id, col_id), rsid in singleton_associations.items():\n",
    "    key = pmid, table_id\n",
    "    if key not in n_singletons_by_table: n_singletons_by_table[key] = 0\n",
    "    n_singletons_by_table[key] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a list valid relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine all of the above relations into a single set of associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7241 associations, e.g.:\n",
      "[('21738491', 'rs12143842', (1, 3, 2), ('Sudden Cardiac Death', 'QT')), ('20585627', 'rs12931267', (2, 8, 1), ('Common Traits', 'Red hair')), ('17903295', 'rs2543600', (3, 14, 2), ('Age-Related Phenotypes|Longevity', 'Age at death')), ('20838585', 'rs726914', (0, 16, 3), ('Cardiovascular Disease', 'systolic blood pressure')), ('20526338', 'rs4311994', (1, 13, 0), ('Platelet Aggregation', 'Epi 2 u M'))]\n",
      "There were 433 singletons\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean(phen):\n",
    "    phen = re.sub('[)():.]+', '', phen)\n",
    "    phen = re.sub('^or ', '', phen)\n",
    "    phen = phen.strip()\n",
    "    return phen\n",
    "\n",
    "associations = []\n",
    "\n",
    "tables_found = {(pmid, table_id) for pmid, table_id, _, _, _ in pval_table_associations} # with pvalues\n",
    "tables_found.update(non_gwas_tables)\n",
    "\n",
    "# record table associations wth pval < 1e-5 or no pval reported\n",
    "chosen_rsids = set()\n",
    "for (pmid, table_id, row_id, col_id), (rsid, loc_phen) in phen_table_associations.items():\n",
    "    pvals = pval_table_associations.get((pmid, table_id, row_id, col_id, rsid), [])\n",
    "    glob_phen = clean(phen_text_associations[pmid])\n",
    "    if (pvals and 10**min(pvals) < 1e-5) or (not pvals and (pmid, table_id) not in tables_found):\n",
    "        associations.append((pmid, rsid, (table_id, row_id, col_id), (glob_phen, loc_phen)))\n",
    "        chosen_rsids.add((pmid, table_id, row_id, col_id, rsid))\n",
    "\n",
    "\n",
    "# record associations with no local phenotype\n",
    "for (pmid, table_id, row_id, col_id, rsid), pvals in pval_table_associations.items():\n",
    "    # skip low-pvalue snps and snps that we already added\n",
    "    if pvals and 10**min(pvals) > 1e-5: continue\n",
    "    if (pmid, table_id, row_id, col_id, rsid) in chosen_rsids: continue\n",
    "    \n",
    "    # append with global phenotype\n",
    "    phen = clean(phen_text_associations[pmid])\n",
    "    associations.append((pmid, rsid, (table_id, row_id, col_id), (phen, '')))    \n",
    "    chosen_rsids.add((pmid, table_id, row_id, col_id, rsid))\n",
    "\n",
    "# record singletons\n",
    "n_singletons_added = 0\n",
    "for (pmid, table_id, row_id, col_id), rsid in singleton_associations.items():\n",
    "    if (pmid, table_id, row_id, col_id, rsid) in chosen_rsids: continue\n",
    "    if (pmid, table_id) in tables_found: continue\n",
    "    if n_singletons_by_table[(pmid, table_id)] < 30: continue\n",
    "    phen = clean(phen_text_associations[pmid])\n",
    "    associations.append((pmid, rsid, (table_id, row_id, col_id), (phen, ''))) \n",
    "    n_singletons_added += 1\n",
    "\n",
    "print len(associations), 'associations, e.g.:'\n",
    "print associations[:5]    \n",
    "print 'There were %d singletons' % n_singletons_added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the associations extracted by our system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('results/associations.tsv', 'w') as f:\n",
    "    for (pmid, rsid, (table_id, row_id, col_id), (glob_phen, loc_phen)) in associations:\n",
    "        pvals = pval_table_associations.get((pmid, table_id, row_id, col_id, rsid), [])\n",
    "        pval = min(pvals) if pvals else -1000\n",
    "        loc_phen = '-' if not loc_phen else loc_phen\n",
    "\n",
    "        f.write('%s\\t%s\\t%s\\t%s\\t%f\\n' % (pmid, rsid, glob_phen, loc_phen, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to evaluate these relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing to GWAS Central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to evalaute the recall relative to existing databases.\n",
    "\n",
    "We start with GWAS Central, which is more extensive than GWAS Catalog (for papers up to ~2013), and which contains very precise phenotype labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 documents, 6760 associations\n"
     ]
    }
   ],
   "source": [
    "from db.kb import KnowledgeBase\n",
    "\n",
    "kb = KnowledgeBase()\n",
    "assocs = [assoc for pmid in pmids for assoc in kb.assoc_by_pmid(pmid) if assoc.source == 'gwas_central' and assoc.pvalue < 1e-5]\n",
    "# assocs = [assoc for pmid in pmids for assoc in kb.assoc_by_pmid(pmid) if assoc.source == 'gwas_central']\n",
    "\n",
    "print '%d documents, %d associations' % (len(pmids), len(assocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up map of GWC to GwasKB phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each database uses different words to describe phenotypes (words chosen by the human curators), we need a mapping between equivalent phenotype names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell records phenotypes associated with each (pmid, rsid) pair\n",
    "# in both our relations and ones in GWC.\n",
    "\n",
    "rel_dict = { (pmid, rsid) : set() for (pmid, rsid, _, _) in associations }\n",
    "for (pmid, rsid, loc, phen) in associations:\n",
    "    rel_dict[(pmid, rsid)].add(phen)\n",
    "\n",
    "gold_rel_dict = { (a.paper.pubmed_id, a.snp.rs_id) : set() for a in assocs }\n",
    "for a in assocs:\n",
    "    gold_rel_dict[(a.paper.pubmed_id, a.snp.rs_id)].add(a.phenotype.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a map of all potential matches. \n",
    "\n",
    "Phenotypes `p1`, `p2` could match if we find `(pmid, rsid, p1)` in GWC and\n",
    "`(pmid, rsid, p2)` in our relations.\n",
    "\n",
    "We save this to a file and manually specify if each `(p1, p2)` are \n",
    "equivalent. We can also load existing mappings via the `phen_scores` dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_set = set()\n",
    "for a in assocs:\n",
    "    s1 = gold_rel_dict[(a.paper.pubmed_id, a.snp.rs_id)]\n",
    "    s2 = rel_dict.get((str(a.paper.pubmed_id), a.snp.rs_id), None)\n",
    "    if s1 and s2:\n",
    "        for name1 in s1:\n",
    "            for name2a, name2b in s2:\n",
    "                name1 = str(name1)\n",
    "                try:\n",
    "                    score = phen_scores.get((name1.lower(), name2a.lower(), name2b.lower()), '')\n",
    "                except:\n",
    "                    score = ''\n",
    "                out_set.add('%s\\t%s\\t%s\\t%s\\n' % (name1, name2a, name2b, score))\n",
    "\n",
    "with open('phenotype.mapping.tsv', 'w') as f:                    \n",
    "    for out_str in out_set:\n",
    "        f.write(out_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads our pre-annotated mapping of phenotypes.\n",
    "\n",
    "Each pair of phenotypes has a score: 0: incorrect, 1: incorrect because acronym could not be resolve, 2: generally correct, but imprecise, 3: fully correct (at least as precise as the human-created label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mapping for 490 relations.\n"
     ]
    }
   ],
   "source": [
    "phen_map = dict()\n",
    "phen_scores = dict()\n",
    "with open('util/phenotype.mapping.annotated.tsv') as f:                    \n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        fields = [re.sub('\"', '', f) for f in fields]\n",
    "        orig_name, glob_name, loc_name, score = fields\n",
    "\n",
    "        phen_scores[(orig_name.lower(), glob_name.lower(), loc_name.lower())] = score\n",
    "        # change the tuple below to ('3',) in order to look at only maximally \n",
    "        # precise phenotypes\n",
    "        if score in ('2', '3',):\n",
    "            key = (glob_name, loc_name)\n",
    "            if key not in phen_map: phen_map[key] = set()\n",
    "            phen_map[key].add(orig_name) \n",
    "\n",
    "print 'Loaded mapping for %d relations.' % len(phen_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at recall relative to GWAS Central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute recall over the subset of \"recoverable\" relations, which are ones that are found in the paper XML body. The following function determines if an RSID is present anywhere in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def paper_contains(pmid, quote):\n",
    "    with open('../data/db/papers/%d.xml' % pmid) as f:\n",
    "        txt = f.read()\n",
    "        return True if re.search(quote, txt) else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use our mapping to comapre against GWAS Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly identifed relations: 2448\n",
      "Incorrectly identifed b/c of wrong phenotype: 69\n",
      "Relations not found at all: 491\n",
      "Total relations in GWC: 3008\n",
      "Papers with most missed relations: [(17903301, 18), (17903305, 17), (19197348, 16), (18159244, 15), (23400010, 14), (21810271, 11), (24121790, 10), (24058526, 10), (22747683, 9), (22216198, 8)]\n"
     ]
    }
   ],
   "source": [
    "confirmed_assocs_gwcen = list()\n",
    "\n",
    "# display directly the results we found\n",
    "n_correct, n_imprecise, n_missing, n_wrong, n_total, n_new = 0, 0, 0, 0, 0, 0\n",
    "invalid_per_paper = { a.paper.pubmed_id : 0 for a in assocs }\n",
    "seen = set()\n",
    "for a in assocs:\n",
    "    if (a.paper.pubmed_id, a.snp.rs_id, a.phenotype.name) in seen: continue\n",
    "    seen.add((a.paper.pubmed_id, a.snp.rs_id, a.phenotype.name))\n",
    "    \n",
    "    gold_phen_set = {a.phenotype.name} # gwc phenotype string\n",
    "    # load the set of gwaskb phenotypes to which the snp was mapped in this paper\n",
    "    pred_phen_set = rel_dict.get((str(a.paper.pubmed_id), a.snp.rs_id), {}) \n",
    "    # translate these phenotypes into gwc phenotypes using our map\n",
    "    pred_phen_transl_set = {m for p in pred_phen_set for m in phen_map.get(p, {})}\n",
    "\n",
    "    if gold_phen_set & pred_phen_transl_set: \n",
    "        n_correct += 1\n",
    "        n_total += 1\n",
    "        # record the corresponding gwaskb associations as having been correctly recovered\n",
    "        correct_phenotypes = [p for p in pred_phen_set if phen_map.get(p, set()) & gold_phen_set]\n",
    "        for p in correct_phenotypes:\n",
    "            confirmed_assocs_gwcen.append( (str(a.paper.pubmed_id), a.snp.rs_id, p) )\n",
    "    else:\n",
    "        if paper_contains(a.paper.pubmed_id, a.snp.rs_id):\n",
    "            # this can be used to diagnose errors\n",
    "            if a.paper.pubmed_id == 888:\n",
    "                # print phenotypes\n",
    "                print a.snp.rs_id, gold_phen_set, pred_phen_set, pred_phen_transl_set\n",
    "            if pred_phen_set:\n",
    "                n_wrong += 1\n",
    "            else:\n",
    "                n_missing += 1\n",
    "            n_total += 1\n",
    "            invalid_per_paper[a.paper.pubmed_id] += 1\n",
    "\n",
    "print 'Correctly identifed relations:', n_correct\n",
    "print 'Incorrectly identifed b/c of wrong phenotype:', n_wrong\n",
    "print 'Relations not found at all:', n_missing\n",
    "print 'Total relations in GWC:', n_total\n",
    "\n",
    "print 'Papers with most missed relations:', sorted(invalid_per_paper.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to GWAS Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we repeat the same analysis with GWAS Catalog relations.\n",
    "\n",
    "GWAS Catalog uses less precise phenotypes, but contains many recent papers that are not in GWAS Central."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 documents, 9747 associations\n"
     ]
    }
   ],
   "source": [
    "from db.kb import KnowledgeBase\n",
    "\n",
    "kb = KnowledgeBase()\n",
    "assocs = [assoc for pmid in pmids for assoc in kb.assoc_by_pmid(pmid) if assoc.source == 'gwas_catalog' and assoc.pvalue < 1e-5]\n",
    "\n",
    "print '%d documents, %d associations' % (len(pmids), len(assocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up map of GwasKB to GWASCat phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a phenotype map in the same way as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_dict = { (pmid, rsid) : set() for (pmid, rsid, _, _) in associations }\n",
    "for (pmid, rsid, loc, phen) in associations:\n",
    "    rel_dict[(pmid, rsid)].add(phen)\n",
    "\n",
    "gold_rel_dict = { (a.paper.pubmed_id, a.snp.rs_id) : set() for a in assocs }\n",
    "for a in assocs:\n",
    "    gold_rel_dict[(a.paper.pubmed_id, a.snp.rs_id)].add(a.phenotype.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_set = set()\n",
    "for a in assocs:\n",
    "    s1 = gold_rel_dict[(a.paper.pubmed_id, a.snp.rs_id)]\n",
    "    s2 = rel_dict.get((str(a.paper.pubmed_id), a.snp.rs_id), None)\n",
    "    if s1 and s2:\n",
    "        for name1 in s1:\n",
    "            for name2a, name2b in s2:\n",
    "                name1 = str(name1)\n",
    "                score = phen_scores.get((name1.lower(), name2a.lower(), name2b.lower()), '')\n",
    "                out_set.add('%s\\t%s\\t%s\\t%s\\n' % (name1, name2a, name2b, score))\n",
    "\n",
    "with open('phenotype.mapping.gwascat.tsv', 'w') as f:                    \n",
    "    for out_str in out_set:\n",
    "        f.write(out_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load pre-labeled annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mapping for 609 relations.\n"
     ]
    }
   ],
   "source": [
    "phen_map = dict()\n",
    "phen_scores = dict()\n",
    "with open('util/phenotype.mapping.gwascat.annotated.tsv') as f:                    \n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        fields = [re.sub('\"', '', f) for f in fields]\n",
    "        orig_name, glob_name, loc_name, score = fields\n",
    "\n",
    "        phen_scores[(orig_name.lower(), glob_name.lower(), loc_name.lower())] = score\n",
    "        # change the tuple below to ('3',) in order to look at only maximally \n",
    "        # precise phenotypes\n",
    "        if score in ('2', '3',):\n",
    "            key = (glob_name, loc_name)\n",
    "            if key not in phen_map: phen_map[key] = set()\n",
    "            phen_map[key].add(orig_name) \n",
    "\n",
    "print 'Loaded mapping for %d relations.' % len(phen_map)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall relative to GWAS Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs1426654 set([u'body mass index']) {} set([])\n",
      "rs10041997 set([u'body mass index (change over time)']) {} set([])\n",
      "rs1347155 set([u'body mass index (change over time)']) {} set([])\n",
      "rs7565158 set([u'body mass index (change over time)']) {} set([])\n",
      "rs6447650 set([u'body mass index (change over time)']) {} set([])\n",
      "rs347313 set([u'body mass index (change over time)']) {} set([])\n",
      "rs8042988 set([u'height']) {} set([])\n",
      "rs4898878 set([u'height']) {} set([])\n",
      "rs1331623 set([u'height']) {} set([])\n",
      "rs12882679 set([u'underweight status']) {} set([])\n",
      "rs6833159 set([u'underweight status']) {} set([])\n",
      "rs1475010 set([u'overweight status']) {} set([])\n",
      "rs12101726 set([u'overweight status']) {} set([])\n",
      "rs1161397 set([u'overweight status']) {} set([])\n",
      "rs955423 set([u'body mass index']) {} set([])\n",
      "rs3096490 set([u'body mass index']) {} set([])\n",
      "3232 101 690 4023\n",
      "Biggest omissions: [(25742292, 18), (19197348, 17), (25133637, 16), (24625756, 14), (23400010, 14), (17903305, 14), (24483146, 13), (21810271, 11), (23770605, 11), (17903301, 11), (24121790, 10), (22747683, 10), (24058526, 10), (25086665, 8), (21738487, 8)]\n"
     ]
    }
   ],
   "source": [
    "confirmed_assocs_gwcat = list()\n",
    "\n",
    "# display directly the results we found\n",
    "n_correct, n_imprecise, n_missing, n_wrong, n_total, n_new = 0, 0, 0, 0, 0, 0\n",
    "invalid_per_paper = { a.paper.pubmed_id : 0 for a in assocs }\n",
    "seen = set()\n",
    "for a in assocs:\n",
    "    if (a.paper.pubmed_id, a.snp.rs_id, a.phenotype.name) in seen: continue\n",
    "    seen.add((a.paper.pubmed_id, a.snp.rs_id, a.phenotype.name))\n",
    "    \n",
    "    gold_phen_set = {a.phenotype.name} # gwc phenotype string\n",
    "    # load the set of gwaskb phenotypes to which the snp was mapped in this paper\n",
    "    pred_phen_set = rel_dict.get((str(a.paper.pubmed_id), a.snp.rs_id), {}) \n",
    "    # translate these phenotypes into gwc phenotypes using our map\n",
    "    pred_phen_transl_set = {m for p in pred_phen_set for m in phen_map.get(p, {})}\n",
    "\n",
    "    if gold_phen_set & pred_phen_transl_set: \n",
    "        n_correct += 1\n",
    "        n_total += 1\n",
    "        # record the corresponding gwaskb associations as having been correctly recovered\n",
    "        correct_phenotypes = [p for p in pred_phen_set if phen_map.get(p, set()) & gold_phen_set]\n",
    "        for p in correct_phenotypes:\n",
    "            confirmed_assocs_gwcat.append( (str(a.paper.pubmed_id), a.snp.rs_id, p) )\n",
    "        \n",
    "    else:\n",
    "        if paper_contains(a.paper.pubmed_id, a.snp.rs_id):\n",
    "            if a.paper.pubmed_id == 25133637:\n",
    "                print a.snp.rs_id, gold_phen_set, pred_phen_set, pred_phen_transl_set\n",
    "            if pred_phen_set:\n",
    "                n_wrong += 1\n",
    "            else:\n",
    "                n_missing += 1\n",
    "            n_total += 1\n",
    "            invalid_per_paper[a.paper.pubmed_id] += 1\n",
    "\n",
    "print n_correct, n_wrong, n_missing, n_total\n",
    "\n",
    "print 'Biggest omissions:', sorted(invalid_per_paper.items(), key=lambda x: x[1], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually evaluating precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure precision over associations that haven't been confirmed by either GWAS Catalog or GWAS Central."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relations in GwasKB: 6376\n",
      "Relations confirmed via GWAS Central: 2438\n",
      "Relations confirmed via GWAS Catalog: 3235\n",
      "Relations confirmed via at least one database: 3452\n",
      "Unconfirmed assocs: 2924\n"
     ]
    }
   ],
   "source": [
    "assocs_gwdb = set([(pmid, rsid, phen) for pmid, rsid, _, phen in associations])\n",
    "print 'Relations in GwasKB: %d' % len(assocs_gwdb)\n",
    "\n",
    "confirmed_assocs_gwcen, confirmed_assocs_gwcat = set(confirmed_assocs_gwcen), set(confirmed_assocs_gwcat)\n",
    "print 'Relations confirmed via GWAS Central: %d' % len(confirmed_assocs_gwcen)\n",
    "print 'Relations confirmed via GWAS Catalog: %d' % len(confirmed_assocs_gwcat)\n",
    "\n",
    "confirmed_assocs = (assocs_gwdb & set(confirmed_assocs_gwcen)) | (assocs_gwdb & set(confirmed_assocs_gwcat))\n",
    "unconfirmed_assocs = assocs_gwdb - confirmed_assocs\n",
    "\n",
    "print 'Relations confirmed via at least one database: %d' % len(confirmed_assocs)\n",
    "print 'Unconfirmed assocs: %d' % len(unconfirmed_assocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write down the confimred and unconfirmed associations that we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('results/associations.new.tsv', 'w') as f: \n",
    "    for (pmid, rsid, (table_id, row_id, col_id), (loc_phen, glob_phen)) in sorted(associations):\n",
    "        if (pmid, rsid, (loc_phen, glob_phen)) in unconfirmed_assocs:\n",
    "            pvals = pval_table_associations.get((pmid, table_id, row_id, col_id, rsid), [])\n",
    "            pval = min(pvals) if pvals else -1000\n",
    "            loc_phen = '-' if not loc_phen else loc_phen\n",
    "            f.write('%s\\t%s\\t%s\\t%s\\t%f\\n' % (pmid, rsid, loc_phen, glob_phen, pval))\n",
    "    \n",
    "with open('results/associations.known.tsv', 'w') as f:\n",
    "    for (pmid, rsid, (table_id, row_id, col_id), (loc_phen, glob_phen)) in sorted(associations):\n",
    "        if (pmid, rsid, (loc_phen, glob_phen)) in confirmed_assocs:\n",
    "            pvals = pval_table_associations.get((pmid, table_id, row_id, col_id, rsid), [])\n",
    "            pval = min(pvals) if pvals else -1000\n",
    "            loc_phen = '-' if not loc_phen else loc_phen\n",
    "            f.write('%s\\t%s\\t%s\\t%s\\t%f\\n' % (pmid, rsid, loc_phen, glob_phen, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also going to store all the associations found in GWAS Catalog and GWAS Central in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "gwcat_assocs = [assoc for pmid in pmids for assoc in kb.assoc_by_pmid(pmid) if assoc.source == 'gwas_catalog' and assoc.pvalue < 1e-5]\n",
    "gwcen_assocs = [assoc for pmid in pmids for assoc in kb.assoc_by_pmid(pmid) if assoc.source == 'gwas_central' and assoc.pvalue < 1e-5]\n",
    "\n",
    "with open('util/associations.gwcat.tsv', 'w') as f:\n",
    "    for a in gwcat_assocs:\n",
    "        f.write('%s\\t%s\\t%s\\t%f\\n' % (a.paper.pubmed_id, a.snp.rs_id, a.phenotype.name, np.log(a.pvalue)))\n",
    "        \n",
    "with open('util/associations.gwcen.tsv', 'w') as f:\n",
    "    for a in gwcen_assocs:\n",
    "        f.write('%s\\t%s\\t%s\\t%f\\n' % (a.paper.pubmed_id, a.snp.rs_id, a.phenotype.name, np.log(a.pvalue)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to inverstigate the validity of the new relations that we found, we are going to sample 100 random relations and later ask independent annotators to verify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random \n",
    "U = list(unconfirmed_assocs)\n",
    "random.shuffle(U)\n",
    "random_subset = list(U[:100])\n",
    "random_subset = sorted(random_subset)\n",
    "if False: # write random subset\n",
    "    with open('rels.discovered.tsv', 'w') as f:\n",
    "        for pmid, rsid, (glob_phen, loc_phen) in random_subset:\n",
    "    #         print pmid, rsid, (glob_phen, loc_phen)\n",
    "            f.write('%s\\t%s\\t%s\\t%s\\n' % (pmid, rsid, glob_phen, loc_phen) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at statistics of GWAS Catalog and GWAS Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching over 589 documents\n",
      "Of these, 430 are in GWAS Central\n",
      "\n",
      "GWAS Central has 6086 associations\n",
      "GWAS Catalog has 9747 associations\n",
      "GwasKB has 7241 associations\n",
      "\n",
      "GWAS Central has 5914 significant variant tuples\n",
      "GWAS Catalog has 8384 significant variant tuples\n",
      "GwasKB has 6187 significant variant tuples\n",
      "\n",
      "GWAS Central has 371 unique significant variant tuples\n",
      "GWAS Catalog has 2046 unique significant variant tuples\n",
      "GwasKB has 2788 unique significant variant tuples\n"
     ]
    }
   ],
   "source": [
    "from db.kb import KnowledgeBase\n",
    "\n",
    "# load all the associations in each database\n",
    "kb = KnowledgeBase()\n",
    "gwcen_a = set([(str(a.paper.pubmed_id), a.snp.rs_id, a.phenotype.name) for pmid in pmids for a in kb.assoc_by_pmid(pmid) if a.source == 'gwas_central' and a.pvalue < 1e-5])\n",
    "gwcat_a = [(str(a.paper.pubmed_id), a.snp.rs_id, a.phenotype.name) for pmid in pmids for a in kb.assoc_by_pmid(pmid) if a.source == 'gwas_catalog' and a.pvalue < 1e-5]\n",
    "\n",
    "# how many of these documents were actually in GWAS Central?\n",
    "gwcen_papers = set([a[0] for a in gwcen_a])\n",
    "\n",
    "print 'Searching over %d documents' % len(pmids)\n",
    "print 'Of these, %d are in GWAS Central' % len(gwcen_papers)\n",
    "print\n",
    "print 'GWAS Central has %d associations' % len(gwcen_a)\n",
    "print 'GWAS Catalog has %d associations' % len(gwcat_a)\n",
    "print 'GwasKB has %d associations' % len(associations)\n",
    "print\n",
    "\n",
    "# we can't compare them directly, because phenotypes don't match; insteal we look at (pmid, rsid) tuples\n",
    "gwcen_t = set([ (a[0], a[1]) for a in gwcen_a ])\n",
    "gwcat_t = set([ (a[0], a[1]) for a in gwcat_a ])\n",
    "gwdb_t = set([ (pmid, rsid) for pmid, rsid, _, _ in associations ])\n",
    "\n",
    "print 'GWAS Central has %d significant variant tuples' % len(gwcen_t)\n",
    "print 'GWAS Catalog has %d significant variant tuples' % len(gwcat_t)\n",
    "print 'GwasKB has %d significant variant tuples' % len(gwdb_t)\n",
    "print\n",
    "\n",
    "# how many of these are unique to each database\n",
    "all_t = gwcen_t | gwcat_t | gwdb_t\n",
    "gwcen_t_uq = gwcen_t - gwcat_t - gwdb_t\n",
    "gwcat_t_uq = gwcat_t - gwcen_t - gwdb_t\n",
    "gwdb_t_uq = gwdb_t - gwcen_t - gwcat_t\n",
    "\n",
    "print 'GWAS Central has %d unique significant variant tuples' % len(gwcen_t_uq)\n",
    "print 'GWAS Catalog has %d unique significant variant tuples' % len(gwcat_t_uq)\n",
    "print 'GwasKB has %d unique significant variant tuples' % len(gwdb_t_uq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing associations in a SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in many applications it is preferrable to have the GWAS associations in the form of the structured database. We generate such associations here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a few helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "def normalize_str(s):\n",
    "    s = s.decode('utf-8')\n",
    "    return unicodedata.normalize('NFKD', s).encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format for the phenotype name is: `keyword1|keyword2|...|keywordn(\\\\local_phenotype)`, where the first set of keyword refer to the global phenotype, and the `local_phenotype` is omitted when it is not available (hence we put it in parantheses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from db import db_session\n",
    "from db.schema import *\n",
    "\n",
    "# this assumes that the cells in the first part of the notebook have been executed\n",
    "phen_dict = dict()\n",
    "for (pmid, rsid, (table_id, row_id, col_id), (glob_phen, loc_phen)) in associations:\n",
    "    name = glob_phen + '\\\\\\\\' + loc_phen if loc_phen else glob_phen\n",
    "    name = normalize_str(name)\n",
    "    key = name.lower()\n",
    "    if key not in phen_dict:\n",
    "        phenotype = Phenotype(name=name, source='gwaskb')      \n",
    "        db_session.add(phenotype)\n",
    "        db_session.commit()\n",
    "        phen_dict[key] = phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from db import db_session\n",
    "from db.schema import *\n",
    "\n",
    "for (pmid, rsid, (table_id, row_id, col_id), (glob_phen, loc_phen)) in associations:\n",
    "    snp = db_session.query(SNP).filter(SNP.rs_id==rsid).first()\n",
    "    if not snp:\n",
    "        snp = SNP(rs_id=rsid)\n",
    "        db_session.add(snp)\n",
    "        db_session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from db import db_session\n",
    "from db.schema import *\n",
    "\n",
    "for (pmid, rsid, location, (glob_phen, loc_phen)) in associations:\n",
    "    # retrieve phenotype\n",
    "    name = glob_phen + '\\\\\\\\' + loc_phen if loc_phen else glob_phen\n",
    "    name = normalize_str(name)\n",
    "    key = name.lower()\n",
    "    phenotype = phen_dict[key]\n",
    "    \n",
    "    # retrieve SNP\n",
    "    snp = db_session.query(SNP).filter(SNP.rs_id==rsid).first()\n",
    "    \n",
    "    # retrieve paper\n",
    "    paper = db_session.query(Paper).filter(Paper.pubmed_id==pmid).first()\n",
    "    \n",
    "    # retrieve p-value\n",
    "    pvals = pval_table_associations.get((pmid, table_id, row_id, col_id, rsid), [None])\n",
    "    \n",
    "    # we will store the location in the 'description' field as table_id|row_id|col_id\n",
    "    loc_str = '%d|%d|%d' % location\n",
    "    \n",
    "    # we create one association for each p-value associated with this SNP\n",
    "    for pval in pvals:\n",
    "        db_session.add(Association(\n",
    "            snp=snp,\n",
    "            phenotype=phenotype,\n",
    "            paper=paper,\n",
    "            pvalue=10**pval if pval else None,\n",
    "            source='gwaskb',\n",
    "            description=loc_str\n",
    "          ))\n",
    "\n",
    "db_session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualizing the associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to first plot the distribution of pvalues for confirmed vs. newly-discoreved variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3744 2917\n"
     ]
    }
   ],
   "source": [
    "old_pvals, new_pvals = list(), list()\n",
    "for (pmid, rsid, (table_id, row_id, col_id), (glob_phen, loc_phen)) in associations:\n",
    "        pvals = pval_table_associations.get((pmid, table_id, row_id, col_id, rsid), [])\n",
    "        if not pvals: continue\n",
    "        if (pmid, rsid) in gwcen_t or (pmid, rsid) in gwcat_t:\n",
    "            old_pvals.append(min(pvals))\n",
    "#             old_pvals.extend((pvals))\n",
    "        else:\n",
    "            new_pvals.append(min(pvals))\n",
    "#             new_pvals.extend((pvals))\n",
    "print len(old_pvals), len(new_pvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "stats.probplot([np.exp(p) for p in old_pvals], plot=plt)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEECAYAAAA4Qc+SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110a96c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist([10**(p) for p in old_pvals], bins=np.logspace(-20, -5, 25))\n",
    "plt.gca().set_xscale(\"log\")\n",
    "# plt.ylim(0,900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEECAYAAAA4Qc+SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11134cf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([10**(p) for p in new_pvals], bins=np.logspace(-20, -5, 25))\n",
    "plt.gca().set_xscale(\"log\")\n",
    "# plt.ylim(0,500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
