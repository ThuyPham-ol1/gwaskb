{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Extracting Formation Measurements from Paleontology Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "PARALLEL = 1\n",
    "os.environ['SNORKELDB'] = 'sqlite:///gwas_nature.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.fonduer import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.fonduer.models import candidate_subclass\n",
    "\n",
    "Pvalue = candidate_subclass('Pvalue', ['pvalue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.fonduer import HTMLPreprocessor, OmniParser\n",
    "\n",
    "docs_path = os.environ['DATA'] + '/gwas/db/papers'\n",
    "\n",
    "max_docs = 1000\n",
    "doc_preprocessor = HTMLPreprocessor(docs_path, max_docs=max_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 38min 21s, sys: 19min 55s, total: 58min 17s\n",
      "Wall time: 1h 51min 12s\n"
     ]
    }
   ],
   "source": [
    "corpus_parser = OmniParser(structural=True, lingual=True, visual=False)\n",
    "%time corpus_parser.apply(doc_preprocessor, parallelism=PARALLEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 589\n",
      "Phrases: 1317142\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer.models import Document, Phrase\n",
    "\n",
    "print \"Documents:\", session.query(Document).count()\n",
    "print \"Phrases:\", session.query(Phrase).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "\n",
    "# p-value matcher\n",
    "rgx1 = u'[1-9]\\d?[\\xb7\\.]?\\d*[\\s\\u2009]*[\\xd7\\xb7\\*][\\s\\u2009]*10[\\s\\u2009]*[-\\u2212\\u2013\\u2012][\\s\\u2009]*\\d+'\n",
    "pval_rgx_matcher1 = RegexMatchSpan(rgx=rgx1)\n",
    "rgx2 = u'[1-9]\\d?[\\xb7\\.]?\\d*[\\s\\u2009]*[eE][\\s\\u2009]*[-\\u2212\\u2013\\u2012][\\s\\u2009]*\\d+'\n",
    "pval_rgx_matcher2 = RegexMatchSpan(rgx=rgx2)\n",
    "rgx3 = u'0\\.0000+\\d+'\n",
    "pval_rgx_matcher3 = RegexMatchSpan(rgx=rgx3)\n",
    "pval_rgx_matcher = Union(pval_rgx_matcher1, pval_rgx_matcher2, pval_rgx_matcher3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.fonduer.fonduer.candidates import OmniNgrams\n",
    "\n",
    "heptagrams = OmniNgrams(n_max=7, split_tokens=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "CPU times: user 9min 54s, sys: 7.62 s, total: 10min 2s\n",
      "Wall time: 10min\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer.candidates import CandidateExtractor\n",
    "\n",
    "candidate_extractor = CandidateExtractor(Pvalue, [heptagrams], [pval_rgx_matcher])\n",
    "\n",
    "%time candidate_extractor.apply(docs, split=0, parallelism=PARALLEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specified that these `Candidates` belong to the training set by specifying `split=0`; recall that we're referring to train/dev/test as splits 0/1/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 12309\n"
     ]
    }
   ],
   "source": [
    "candidates = session.query(Pvalue).filter(Pvalue.split == 0).all()\n",
    "print \"Number of candidates:\", len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pvalue_rgx = u'{}|{}|{}'.format(rgx1, rgx2, rgx3)\n",
    "pvalue_matcher = re.compile(pvalue_rgx, flags=(re.I|re.UNICODE))\n",
    "\n",
    "def overlap(a1, b1, a2, b2):\n",
    "    return not (b1 < a2 or a1 > b2)\n",
    "\n",
    "\n",
    "def extract_metadata(phrase):\n",
    "    return [p.text.encode('utf-8') for p in phrase.table.phrases if \n",
    "        p.row_end <= 2 and\n",
    "        overlap(p.col_start, p.col_end, phrase.col_start, phrase.col_end) and \n",
    "        not pvalue_matcher.match(p.text)]\n",
    "\n",
    "\n",
    "def make_line(phrase): \n",
    "    doc_id = phrase.document.name\n",
    "    table_idx = phrase.table.position + 1 # make table_idx 1-indexed\n",
    "    row = phrase.row_start\n",
    "    col = phrase.col_start\n",
    "    pvalue = c[0].get_span().ljust(10) # pad for uniform width\n",
    "    metadata = extract_metadata(phrase)\n",
    "#     print('{}: {}\\t{}'.format(doc_id, pvalue, metadata))\n",
    "    line = map(lambda x: unicode(x).encode('utf-8'), [doc_id, table_idx, row, col, pvalue, metadata])\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "OUTFILE = 'pvalue_metadata.tsv'\n",
    "\n",
    "with open(OUTFILE, 'wb') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='\\t', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow([\"doc_id\", \"table_index\", \"rows\", \"cols\", \"p-value\", \"metadata\"])\n",
    "    for c in candidates:\n",
    "        phrase = c.get_parent()\n",
    "        if not phrase.table:\n",
    "            continue\n",
    "        line = make_line(phrase)\n",
    "        writer.writerow(line)\n",
    "        # print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match discovered p-values with other information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "pvalue_dict = defaultdict(list)\n",
    "for c in candidates:\n",
    "    phrase = c.get_parent()\n",
    "    if not phrase.table:\n",
    "        continue\n",
    "    line = make_line(phrase)\n",
    "    doc_id, table_idx, row, col, pvalue, metadata = line\n",
    "    \n",
    "    pvalue = pvalue.replace(' ', '')\n",
    "    pvalue = pvalue.replace('×10', 'E')\n",
    "    pvalue = pvalue.replace('·10', 'E')\n",
    "    try:\n",
    "        pvalue = float(pvalue)\n",
    "        if not pvalue:\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    table_0idx = str(int(table_idx) - 1)\n",
    "    pvalue_log10 = math.log10(pvalue)\n",
    "    pvalue_dict[(doc_id, table_0idx)].append((pvalue_log10, row, col, metadata))\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Source: \"https://raw.githubusercontent.com/kuleshov/gwaskb/master/notebooks/results/nb-output/pval-rsid.filtered.tsv\"\n",
    "rsid_readfile = 'pval-rsid.filtered.csv'\n",
    "rsid_writefile = 'pval-rsid.metadata.csv'\n",
    "\n",
    "with open(rsid_readfile, 'r') as readfile, open(rsid_writefile, 'w') as writefile:\n",
    "    reader = csv.reader(readfile, delimiter='\\t', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer = csv.writer(writefile, delimiter='\\t', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow([\"doc_id\", \"table_index\", \"rows\", \"cols\", \"p-value\", \"metadata\"])\n",
    "    for line in reader:\n",
    "        doc_id, rsid, table, row, col, pval_log10 = line\n",
    "        options = pvalue_dict[(doc_id, table)]\n",
    "        metadata = ''\n",
    "        for opt in options:\n",
    "            if abs(float(pval_log10) - opt[0]) < 0.001:\n",
    "                metadata = opt[-1]\n",
    "                break\n",
    "        line.append(metadata)        \n",
    "        writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
